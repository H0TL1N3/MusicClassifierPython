{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:34:11.080225Z",
     "start_time": "2025-06-16T10:34:03.542410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.optim.adamw import adamw\n",
    "!pip install -q -U \"tensorflow-text\"\n",
    "!pip install -q tf-models-official\n",
    "!pip install transformers datasets torch scikit-learn\n",
    "!pip install -U accelerate\n",
    "!pip install -U transformers\n",
    "!pip install -U evaluate\n",
    "!pip install -U datasets huggingface_hub fsspec\n",
    "!pip install -U scikit-learn"
   ],
   "id": "42bed9af5aad05fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: transformers in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (4.52.4)\r\n",
      "Requirement already satisfied: datasets in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (3.6.0)\r\n",
      "Requirement already satisfied: torch in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (2.6.0)\r\n",
      "Requirement already satisfied: scikit-learn in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (1.7.0)\r\n",
      "Requirement already satisfied: filelock in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (0.33.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (2.32.4)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (20.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (2.3.0)\r\n",
      "Requirement already satisfied: xxhash in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from scikit-learn) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from scikit-learn) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests->transformers) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests->transformers) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests->transformers) (2025.4.26)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: accelerate in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (1.7.0)\r\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from accelerate) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from accelerate) (25.0)\r\n",
      "Requirement already satisfied: psutil in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from accelerate) (7.0.0)\r\n",
      "Requirement already satisfied: pyyaml in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from accelerate) (6.0.2)\r\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from accelerate) (2.6.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from accelerate) (0.33.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from accelerate) (0.5.3)\r\n",
      "Requirement already satisfied: filelock in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.0)\r\n",
      "Requirement already satisfied: requests in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.3)\r\n",
      "Requirement already satisfied: networkx in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: transformers in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (4.52.4)\r\n",
      "Requirement already satisfied: filelock in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (0.33.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (2.32.4)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests->transformers) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests->transformers) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests->transformers) (2025.4.26)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: evaluate in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (0.4.3)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from evaluate) (3.6.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from evaluate) (1.26.4)\r\n",
      "Requirement already satisfied: dill in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from evaluate) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from evaluate) (2.3.0)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from evaluate) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from evaluate) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from evaluate) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from evaluate) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from evaluate) (0.33.0)\r\n",
      "Requirement already satisfied: packaging in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from evaluate) (25.0)\r\n",
      "Requirement already satisfied: filelock in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.3)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2025.4.26)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from pandas->evaluate) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.4)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: datasets in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (3.6.0)\r\n",
      "Requirement already satisfied: huggingface_hub in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (0.33.0)\r\n",
      "Requirement already satisfied: fsspec in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (2025.3.0)\r\n",
      "Collecting fsspec\r\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: filelock in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (3.18.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (1.26.4)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (20.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (2.3.0)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: packaging in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from datasets) (6.0.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from huggingface_hub) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from huggingface_hub) (1.1.3)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: scikit-learn in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (1.7.0)\r\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from scikit-learn) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from scikit-learn) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:34:11.344852Z",
     "start_time": "2025-06-16T10:34:11.157588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())  # Should return True if GPU is ready"
   ],
   "id": "b94dcd7e5d027e83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset load and processing",
   "id": "e869cd9f4b8467f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:34:20.751496Z",
     "start_time": "2025-06-16T10:34:11.351525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datasets\n",
    "\n",
    "dataset1_raw = datasets.load_dataset(\"ThatOneShortGuy/SongLyrics\", split=\"train\", num_proc=3)\n",
    "dataset2_raw = datasets.load_dataset(\"sebastiandizon/genius-song-lyrics\", split=\"train\", num_proc=3)\n",
    "dataset3_raw = datasets.load_dataset(\"amishshah/song_lyrics\", split=\"train\", num_proc=3)"
   ],
   "id": "3e8d43fa655bba6d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vm/Documents/lu/valTeh/proj/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:34:20.963072Z",
     "start_time": "2025-06-16T10:34:20.757567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def language_filter(entry: dict, *extra_args):\n",
    "    return entry['language'] == 'en'\n",
    "\n",
    "\n",
    "dataset2_raw = dataset2_raw.filter(language_filter, num_proc=3)"
   ],
   "id": "ed9e4747cab61efc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:34:21.015134Z",
     "start_time": "2025-06-16T10:34:20.969290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make so that all datasets have equal fields\n",
    "print(\"before cleanup:\")\n",
    "print(dataset1_raw)\n",
    "print(dataset2_raw)\n",
    "print(dataset3_raw)\n",
    "\n",
    "dataset1 = dataset1_raw\n",
    "dataset2 = dataset2_raw\n",
    "dataset3 = dataset3_raw\n",
    "\n",
    "dataset1 = dataset1.remove_columns(\n",
    "    [\"id\", \"artist\", 'image_url', 'release_day', 'release_month', 'release_year', 'pageviews'])\n",
    "dataset2 = dataset2.remove_columns(['artist', 'year', 'views', 'features', 'id', 'language_cld3', 'language_ft'])\n",
    "dataset3 = dataset3.remove_columns(['Unnamed: 0'])\n",
    "\n",
    "dataset1 = dataset1.remove_columns(['title'])\n",
    "dataset2 = dataset2.remove_columns(['title', 'language'])\n",
    "dataset3 = dataset3.remove_columns(['title'])\n",
    "\n",
    "dataset1 = dataset1.rename_column('genre', 'tag')\n",
    "\n",
    "# language_column = [\"en\"] * len(dataset1)\n",
    "# dataset1 = dataset1.add_column(\"language\", language_column)\n",
    "\n",
    "# language_column = [\"en\"] * len(dataset3)\n",
    "# dataset3 = dataset3.add_column(\"language\", language_column)\n",
    "\n",
    "print(\"after cleanup:\")\n",
    "print(dataset1)\n",
    "print(dataset2)\n",
    "print(dataset3)"
   ],
   "id": "309a82e1d6737791",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before cleanup:\n",
      "Dataset({\n",
      "    features: ['id', 'title', 'artist', 'lyrics', 'genre', 'image_url', 'release_day', 'release_month', 'release_year', 'pageviews'],\n",
      "    num_rows: 451736\n",
      "})\n",
      "Dataset({\n",
      "    features: ['title', 'tag', 'artist', 'year', 'views', 'features', 'lyrics', 'id', 'language_cld3', 'language_ft', 'language'],\n",
      "    num_rows: 3374198\n",
      "})\n",
      "Dataset({\n",
      "    features: ['Unnamed: 0', 'title', 'tag', 'lyrics'],\n",
      "    num_rows: 3374198\n",
      "})\n",
      "after cleanup:\n",
      "Dataset({\n",
      "    features: ['lyrics', 'tag'],\n",
      "    num_rows: 451736\n",
      "})\n",
      "Dataset({\n",
      "    features: ['tag', 'lyrics'],\n",
      "    num_rows: 3374198\n",
      "})\n",
      "Dataset({\n",
      "    features: ['tag', 'lyrics'],\n",
      "    num_rows: 3374198\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:34:21.987068Z",
     "start_time": "2025-06-16T10:34:21.021878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#split datasets\n",
    "dataset1_split = dataset1.train_test_split(test_size=0.1)\n",
    "dataset2_split = dataset2.train_test_split(test_size=0.1)\n",
    "dataset3_split = dataset3.train_test_split(test_size=0.1)\n",
    "\n",
    "print(dataset1_split)\n",
    "print(dataset2_split)\n",
    "print(dataset3_split)"
   ],
   "id": "e731312bf7e45a8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['lyrics', 'tag'],\n",
      "        num_rows: 406562\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['lyrics', 'tag'],\n",
      "        num_rows: 45174\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tag', 'lyrics'],\n",
      "        num_rows: 3036778\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tag', 'lyrics'],\n",
      "        num_rows: 337420\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tag', 'lyrics'],\n",
      "        num_rows: 3036778\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tag', 'lyrics'],\n",
      "        num_rows: 337420\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:34:22.111644Z",
     "start_time": "2025-06-16T10:34:21.991249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#combine datasets in to 2 large ones, train and test\n",
    "dataset_train = datasets.concatenate_datasets(\n",
    "    [dataset1_split[\"train\"], dataset2_split[\"train\"], dataset3_split[\"train\"]])\n",
    "dataset_test = datasets.concatenate_datasets([dataset1_split[\"test\"], dataset2_split[\"test\"], dataset3_split[\"test\"]])\n",
    "print(dataset_train)\n",
    "print(dataset_test)"
   ],
   "id": "61855c9acf959218",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['lyrics', 'tag'],\n",
      "    num_rows: 6480118\n",
      "})\n",
      "Dataset({\n",
      "    features: ['lyrics', 'tag'],\n",
      "    num_rows: 720014\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:34:46.793416Z",
     "start_time": "2025-06-16T10:34:22.116510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Before normalization and tag combination:\")\n",
    "# Group, count\n",
    "train_counted = Counter(dataset_train['tag'])\n",
    "test_counted = Counter(dataset_test['tag'])\n",
    "\n",
    "# Special variable for not showing records when their count is lower than...\n",
    "MIN_COUNT = 1000\n",
    "\n",
    "# Print (and also populate tag list)\n",
    "print(\"In train:\")\n",
    "for tag, count in train_counted.items():\n",
    "    if (count < MIN_COUNT):\n",
    "        continue\n",
    "    print(f\"Tag {tag}: {count} records\")\n",
    "\n",
    "print(\"In test:\")\n",
    "for tag, count in test_counted.items():\n",
    "    if (count < MIN_COUNT):\n",
    "        continue\n",
    "    print(f\"Tag {tag}: {count} records\")"
   ],
   "id": "287f9b50f12d032a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization and tag combination:\n",
      "In train:\n",
      "Tag Jazz: 5452 records\n",
      "Tag Country: 38908 records\n",
      "Tag Pop: 34829 records\n",
      "Tag PopRock: 5523 records\n",
      "Tag Rock: 75799 records\n",
      "Tag RBSoul: 19265 records\n",
      "Tag Metal: 6248 records\n",
      "Tag Alternative: 27065 records\n",
      "Tag Hip-HopRap: 28629 records\n",
      "Tag Unknown: 38149 records\n",
      "Tag Indie Rock: 4008 records\n",
      "Tag Soul: 4793 records\n",
      "Tag WorldInternational: 5063 records\n",
      "Tag Latin: 8330 records\n",
      "Tag Hard Rock: 2087 records\n",
      "Tag DanceElectronic: 2124 records\n",
      "Tag Traditional Country: 1123 records\n",
      "Tag BluesFolk: 5321 records\n",
      "Tag Hip-Hop: 12023 records\n",
      "Tag Meme Rap: 1099 records\n",
      "Tag WorldReggae: 5535 records\n",
      "Tag Dance: 1566 records\n",
      "Tag Rap: 5201 records\n",
      "Tag SingerSongwriter: 3253 records\n",
      "Tag Disco: 1534 records\n",
      "Tag Classic Rock: 5251 records\n",
      "Tag Punk: 1889 records\n",
      "Tag Alternative Country: 1805 records\n",
      "Tag Electronic: 3304 records\n",
      "Tag Christian  Gospel: 1741 records\n",
      "Tag ElectronicDance: 2369 records\n",
      "Tag Easy ListeningVocal: 2205 records\n",
      "Tag Contemporary Country: 2493 records\n",
      "Tag Rock  Roll: 1355 records\n",
      "Tag RB: 2710 records\n",
      "Tag New Wave: 1032 records\n",
      "Tag Folk-Rock: 1228 records\n",
      "Tag Inspirational: 3012 records\n",
      "Tag Reggae: 2887 records\n",
      "Tag Americana: 1401 records\n",
      "Tag House: 1491 records\n",
      "Tag rap: 1736680 records\n",
      "Tag rock: 1139714 records\n",
      "Tag pop: 2508090 records\n",
      "Tag country: 155865 records\n",
      "Tag rb: 279191 records\n",
      "Tag misc: 254016 records\n",
      "In test:\n",
      "Tag Alternative: 2883 records\n",
      "Tag Hip-Hop: 1387 records\n",
      "Tag Rock: 8398 records\n",
      "Tag Pop: 3780 records\n",
      "Tag Country: 4267 records\n",
      "Tag Hip-HopRap: 3193 records\n",
      "Tag Unknown: 4316 records\n",
      "Tag RBSoul: 2148 records\n",
      "Tag rb: 30973 records\n",
      "Tag pop: 279028 records\n",
      "Tag rock: 126902 records\n",
      "Tag rap: 192530 records\n",
      "Tag misc: 27956 records\n",
      "Tag country: 17451 records\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:38:26.933785Z",
     "start_time": "2025-06-16T10:34:46.840607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Manual mapping based on the results given:\n",
    "# Combine similar, exclude unique (classical, regional mexicano...)\n",
    "# Or vague (inspirational, world-international)\n",
    "\n",
    "def mapping_func(row):\n",
    "    # Declaring helper variables here since excluding them from here\n",
    "    # Will fail num_proc attempts.\n",
    "    # Constants to avoid possible misspellings\n",
    "    ROCK_TAG = \"rock\"\n",
    "    POP_TAG = \"pop\"\n",
    "    RAP_TAG = \"rap\"\n",
    "    COUNTRY_TAG = \"country\"\n",
    "    RB_TAG = \"rb\"\n",
    "    MISC_TAG = \"misc\"\n",
    "\n",
    "    # Everything that is not a key in this map will be excluded.\n",
    "    # Keys are normalized to lowercase to account for multiple similar records\n",
    "    # (e.g. both \"Rock\" and \"rock\").\n",
    "    tag_map = {\n",
    "        # Rock\n",
    "        \"rock\": ROCK_TAG,\n",
    "        \"metal\": ROCK_TAG,\n",
    "        \"classic rock\": ROCK_TAG,\n",
    "        \"hard rock\": ROCK_TAG,\n",
    "        \"alternative\": ROCK_TAG,\n",
    "        \"rock  roll\": ROCK_TAG,\n",
    "        \"poprock\": ROCK_TAG,\n",
    "        \"folk-rock\": ROCK_TAG,\n",
    "        \"punk\": ROCK_TAG,\n",
    "        \"indie rock\": ROCK_TAG,\n",
    "        # Pop\n",
    "        \"pop\": POP_TAG,\n",
    "        \"disco\": POP_TAG,\n",
    "        \"k-pop\": POP_TAG,\n",
    "        \"j-pop\": POP_TAG,\n",
    "        # Rap\n",
    "        \"rap\": RAP_TAG,\n",
    "        \"hip-hoprap\": RAP_TAG,\n",
    "        \"anime rap\": RAP_TAG,\n",
    "        \"hip-hop\": RAP_TAG,\n",
    "        \"meme rap\": RAP_TAG,\n",
    "        # Country\n",
    "        \"country\": COUNTRY_TAG,\n",
    "        \"outlaw country\": COUNTRY_TAG,\n",
    "        \"contemporary country\": COUNTRY_TAG,\n",
    "        # R'n'B\n",
    "        \"rb\": RB_TAG,\n",
    "        \"rbsoul\": RB_TAG,\n",
    "        \"r&b\": RB_TAG,\n",
    "        \"worldreggae\": RB_TAG,\n",
    "        # Misc\n",
    "        # \"misc\": MISC_TAG,\n",
    "        # \"unknown\": MISC_TAG,\n",
    "        # \"danceelectronic\": MISC_TAG,\n",
    "        # \"electronic\": MISC_TAG\n",
    "    }\n",
    "    # Normalize tag\n",
    "    row_tag = row[\"tag\"].strip().lower()\n",
    "    if row_tag in tag_map:\n",
    "        new_tag = tag_map[row_tag]\n",
    "        return {\"tag\": new_tag}\n",
    "    return {\"tag\": \"rm\"}\n",
    "\n",
    "\n",
    "def mapping_func_filter(entry: dict, *extra_args):\n",
    "    return entry[\"tag\"] != 'rm'\n",
    "\n",
    "\n",
    "# Normalize tags\n",
    "dataset_train = dataset_train.map(mapping_func, num_proc=3)\n",
    "dataset_train = dataset_train.filter(mapping_func_filter, num_proc=3)\n",
    "# Normalize tags\n",
    "dataset_test = dataset_test.map(mapping_func, num_proc=3)\n",
    "dataset_test = dataset_test.filter(mapping_func_filter, num_proc=3)"
   ],
   "id": "d1ae1bc5a5e41856",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=3): 100%|| 6480118/6480118 [03:06<00:00, 34706.73 examples/s]\n",
      "Filter (num_proc=3): 100%|| 6480118/6480118 [00:08<00:00, 725957.22 examples/s]\n",
      "Map (num_proc=3): 100%|| 720014/720014 [00:22<00:00, 31821.89 examples/s]\n",
      "Filter (num_proc=3): 100%|| 720014/720014 [00:00<00:00, 750893.65 examples/s]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:38:48.684224Z",
     "start_time": "2025-06-16T10:38:26.946765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"After normalization and tag combination:\")\n",
    "# Group, count\n",
    "train_counted = Counter(dataset_train['tag'])\n",
    "test_counted = Counter(dataset_test['tag'])\n",
    "\n",
    "print(\"In train:\")\n",
    "for tag, count in train_counted.items():\n",
    "    print(f\"Tag {tag}: {count} records\")\n",
    "\n",
    "print(\"In test:\")\n",
    "for tag, count in test_counted.items():\n",
    "    print(f\"Tag {tag}: {count} records\")\n"
   ],
   "id": "7197c231d4c0122f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After normalization and tag combination:\n",
      "In train:\n",
      "Tag country: 197579 records\n",
      "Tag pop: 2544888 records\n",
      "Tag rock: 1270167 records\n",
      "Tag rb: 306701 records\n",
      "Tag rap: 1784096 records\n",
      "In test:\n",
      "Tag rock: 141263 records\n",
      "Tag rap: 197916 records\n",
      "Tag pop: 283024 records\n",
      "Tag country: 22045 records\n",
      "Tag rb: 34076 records\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:44:05.771166Z",
     "start_time": "2025-06-16T10:39:53.941104Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # TODO: Balance out by reducing the count of rows in each set\n",
    "# to the smallest number found in the counter after normalization.\n",
    "# In our case, it will be balanced by \"country\",\n",
    "# where only 210'155(train)/23'127(test) rows are present.\n",
    "import random\n",
    "\n",
    "\n",
    "def balance_dataset(dataset, label_column=\"label\", seed=42):\n",
    "    # Count examples per class\n",
    "    label_counts = Counter(dataset[label_column])\n",
    "    min_count = min(label_counts.values())\n",
    "\n",
    "    print(f\"Class distribution before balancing: {label_counts}\")\n",
    "    print(f\"Downsampling to {min_count} examples per class.\")\n",
    "\n",
    "    # Group examples by label\n",
    "    label_to_examples = {label: [] for label in label_counts}\n",
    "    for i, example in enumerate(dataset):\n",
    "        label_to_examples[example[label_column]].append(i)\n",
    "\n",
    "    # Sample min_count examples from each class\n",
    "    balanced_indices = []\n",
    "    for label, indices in label_to_examples.items():\n",
    "        sampled = random.Random(seed).sample(indices, min_count)\n",
    "        balanced_indices.extend(sampled)\n",
    "\n",
    "    # Select the balanced subset\n",
    "    balanced_dataset = dataset.select(balanced_indices)\n",
    "\n",
    "    # Check new distribution\n",
    "    new_counts = Counter(balanced_dataset[label_column])\n",
    "    print(f\"Class distribution after balancing: {new_counts}\")\n",
    "    return balanced_dataset\n",
    "\n",
    "\n",
    "# do smart balance, remove equally distributed\n",
    "dataset_train_filter = balance_dataset(dataset_train, label_column=\"tag\")\n",
    "\n"
   ],
   "id": "2b4074d25f66f449",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before balancing: Counter({'pop': 2544888, 'rap': 1784096, 'rock': 1270167, 'rb': 306701, 'country': 197579})\n",
      "Downsampling to 197579 examples per class.\n",
      "Class distribution after balancing: Counter({'country': 197579, 'pop': 197579, 'rock': 197579, 'rb': 197579, 'rap': 197579})\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:44:39.610950Z",
     "start_time": "2025-06-16T10:44:12.030590Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_test = balance_dataset(dataset_test, label_column=\"tag\")",
   "id": "8d4d11b7b6f160bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before balancing: Counter({'pop': 283024, 'rap': 197916, 'rock': 141263, 'rb': 34076, 'country': 22045})\n",
      "Downsampling to 22045 examples per class.\n",
      "Class distribution after balancing: Counter({'rock': 22045, 'rap': 22045, 'pop': 22045, 'country': 22045, 'rb': 22045})\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:44:59.594650Z",
     "start_time": "2025-06-16T10:44:56.148591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"After Balancing:\")\n",
    "# Group, count\n",
    "train_counted_filter = Counter(dataset_train_filter['tag'])\n",
    "# test_counted = Counter(dataset_test['tag'])\n",
    "\n",
    "print(\"In train:\")\n",
    "for tag, count in train_counted_filter.items():\n",
    "    print(f\"Tag {tag}: {count} records\")\n",
    "\n",
    "dataset_train = dataset_train_filter\n",
    "# print(\"In test:\")\n",
    "# for tag, count in test_counted.items():\n",
    "#     print(f\"Tag {tag}: {count} records\")"
   ],
   "id": "75cec435662eb377",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Balancing:\n",
      "In train:\n",
      "Tag country: 197579 records\n",
      "Tag pop: 197579 records\n",
      "Tag rock: 197579 records\n",
      "Tag rb: 197579 records\n",
      "Tag rap: 197579 records\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:45:26.495390Z",
     "start_time": "2025-06-16T10:44:59.601221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from numpy.random import randint\n",
    "import re\n",
    "\n",
    "# remove any occurrence of [...]\n",
    "rgx = re.compile(r'(\\[)(.)*(])')\n",
    "\n",
    "\n",
    "def cleanup(entry):\n",
    "    entry[\"lyrics\"] = rgx.sub('', entry[\"lyrics\"])\n",
    "    return entry\n",
    "\n",
    "\n",
    "dataset_train = dataset_train.map(cleanup, num_proc=3)\n",
    "dataset_test = dataset_test.map(cleanup, num_proc=3)\n",
    "\n",
    "# what we don't want\n",
    "# exclude_idx = [randint(0, len(dataset_train)) for i in range(int(len(dataset_train) / 3))]\n",
    "\n",
    "# create new dataset exluding those idx\n",
    "# dataset_train = dataset_train.select(exclude_idx)\n",
    "\n",
    "# randomly delete some entries to reduce size\n",
    "# dataset_train = dataset_train.map(lambda example: {\"new_sentence\": example[\"sentence1\"]}, remove_columns=[\"sentence1\"])\n"
   ],
   "id": "769aaf1b1cbbe593",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=3): 100%|| 987895/987895 [00:23<00:00, 41683.41 examples/s]\n",
      "Map (num_proc=3): 100%|| 110225/110225 [00:02<00:00, 39960.85 examples/s]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tokenization",
   "id": "6691f507a9c5e58e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:45:44.164550Z",
     "start_time": "2025-06-16T10:45:26.502585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_mapping = {\"rb\": 0, \"rock\": 1, \"country\": 2, \"pop\": 3, \"rap\": 4}\n",
    "dataset_train = dataset_train.map(lambda x: {\"label\": label_mapping[x[\"tag\"]]}, num_proc=3)\n",
    "dataset_test = dataset_test.map(lambda x: {\"label\": label_mapping[x[\"tag\"]]}, num_proc=3)\n",
    "\n"
   ],
   "id": "319dd9b5cdc841e9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=3): 100%|| 987895/987895 [00:15<00:00, 62463.63 examples/s] \n",
      "Map (num_proc=3): 100%|| 110225/110225 [00:01<00:00, 72371.26 examples/s] \n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:45:45.876749Z",
     "start_time": "2025-06-16T10:45:44.175072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-cased\")"
   ],
   "id": "fb84d4fda3ce54a8",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:47:58.204727Z",
     "start_time": "2025-06-16T10:45:45.885716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"lyrics\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "\n",
    "# Apply the tokenizer to the dataset\n",
    "tokenized_dataset_train = dataset_train.map(tokenize_function, batched=True, num_proc=6)\n",
    "tokenized_dataset_test = dataset_test.map(tokenize_function, batched=True, num_proc=6)\n",
    "\n",
    "print(tokenized_dataset_train[0])\n",
    "# save only 20% from original size\n",
    "tokenized_dataset_train.save_to_disk(\"tokenized_dataset_train\")\n",
    "tokenized_dataset_test.save_to_disk(\"tokenized_dataset_test\")\n",
    "\n"
   ],
   "id": "a9d9c96165ac1406",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=6): 100%|| 987895/987895 [01:45<00:00, 9351.99 examples/s] \n",
      "Map (num_proc=6): 100%|| 110225/110225 [00:11<00:00, 9938.00 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lyrics': \"In a quaint caravan\\nThere's a lady they call the gypsy\\nShe can look in the future\\nAnd drive away all your fears\\n\\nEverything will come right\\nIf you'll only believe the gypsy\\nShe could tell at a glance\\nThat my heart was so full of tears\\n\\nShe looked at my hand and told me\\nMy lover was always true\\nAnd yet in my heart I knew, dear\\nSomebody else was kissing you\\n\\nBut I'll go there again\\n'Cause I want to believe the gypsy\\nThat my lover is true\\nAnd will come back to me someday\\n\\nShe looked at my hand and told me\\nMy lover was always true\\nAnd yet in my heart I knew, dear\\nSomebody else was kissing you\\nBut I'll go there again\\n'Cause I want to believe the gypsy\\nThat my lover is true\\nAnd will come back to me someday\", 'tag': 'country', 'label': 2, 'input_ids': [101, 1130, 170, 186, 6718, 10879, 25490, 1247, 112, 188, 170, 5141, 1152, 1840, 1103, 176, 1183, 12685, 1153, 1169, 1440, 1107, 1103, 2174, 1262, 2797, 1283, 1155, 1240, 10434, 5268, 1209, 1435, 1268, 1409, 1128, 112, 1325, 1178, 2059, 1103, 176, 1183, 12685, 1153, 1180, 1587, 1120, 170, 5410, 1337, 1139, 1762, 1108, 1177, 1554, 1104, 3632, 1153, 1350, 1120, 1139, 1289, 1105, 1500, 1143, 1422, 7559, 1108, 1579, 2276, 1262, 1870, 1107, 1139, 1762, 146, 1450, 117, 7059, 18490, 1950, 1108, 7567, 1128, 1252, 146, 112, 1325, 1301, 1175, 1254, 112, 20111, 146, 1328, 1106, 2059, 1103, 176, 1183, 12685, 1337, 1139, 7559, 1110, 2276, 1262, 1209, 1435, 1171, 1106, 1143, 18361, 1153, 1350, 1120, 1139, 1289, 1105, 1500, 1143, 1422, 7559, 1108, 1579, 2276, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (5/5 shards): 100%|| 987895/987895 [00:13<00:00, 71312.19 examples/s] \n",
      "Saving the dataset (1/1 shards): 100%|| 110225/110225 [00:00<00:00, 659331.28 examples/s]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Balance",
   "id": "aaaaf50fb5b6a24b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:47:58.218697Z",
     "start_time": "2025-06-16T10:47:58.216786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# labels = dataset[\"train\"][\"label\"]\n",
    "# class_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
    "# print(class_weights)"
   ],
   "id": "cbc45fe353ff8bd0",
   "outputs": [],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
